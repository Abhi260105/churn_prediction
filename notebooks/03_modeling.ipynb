{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b5a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Model Training & Evaluation - Customer Churn Prediction\n",
    "# \n",
    "# **Objective:** Train and compare ML models for production churn prediction\n",
    "# \n",
    "# **Models:**\n",
    "# 1. Logistic Regression (Baseline, interpretable)\n",
    "# 2. XGBoost (Production model)\n",
    "# \n",
    "# **Focus:** Business metrics, not just accuracy!\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Setup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Now import works\n",
    "from src.train import ChurnModelTrainer\n",
    "from src.evaluate import ChurnModelEvaluator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Load Engineered Features\n",
    "\n",
    "# %%\n",
    "df = pd.read_csv('../data/processed/churn_features.csv')\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Churn Rate: {df['Churn'].mean()*100:.2f}%\")\n",
    "print(f\"\\nFeatures available: {len(df.columns)}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Quick Data Check\n",
    "\n",
    "# %%\n",
    "# Check for missing values\n",
    "print(\"\\n=== MISSING VALUES CHECK ===\")\n",
    "missing = df.isnull().sum().sum()\n",
    "if missing == 0:\n",
    "    print(\"‚úÖ No missing values!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è {missing} missing values found\")\n",
    "\n",
    "# Check churn distribution\n",
    "print(\"\\n=== CHURN DISTRIBUTION ===\")\n",
    "print(df['Churn'].value_counts())\n",
    "print(f\"\\nClass imbalance ratio: {df['Churn'].value_counts()[0] / df['Churn'].value_counts()[1]:.2f}:1\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Train Models\n",
    "\n",
    "# %%\n",
    "# Initialize trainer\n",
    "trainer = ChurnModelTrainer(features_path='../data/processed/churn_features.csv')\n",
    "\n",
    "# Run training pipeline\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STARTING MODEL TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "trainer.train_pipeline()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Model Performance Comparison\n",
    "\n",
    "# %%\n",
    "# Compare models\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name in ['logistic_regression', 'xgboost']:\n",
    "    results = trainer.results[model_name]\n",
    "    print(f\"\\n{model_name.upper().replace('_', ' ')}:\")\n",
    "    print(f\"  ROC-AUC:   {results['test_auc']:.4f}\")\n",
    "    print(f\"  Recall:    {results['recall']:.4f}\")\n",
    "    print(f\"  Precision: {results['precision']:.4f}\")\n",
    "    print(f\"  F1-Score:  {results['f1']:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Confusion Matrices Visualization\n",
    "\n",
    "# %%\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for idx, (model_name, results) in enumerate(trainer.results.items()):\n",
    "    cm = results['confusion_matrix']\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx])\n",
    "    axes[idx].set_title(f'{model_name.replace(\"_\", \" \").title()} - Confusion Matrix', \n",
    "                        fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Actual')\n",
    "    axes[idx].set_xlabel('Predicted')\n",
    "    axes[idx].set_xticklabels(['No Churn', 'Churn'])\n",
    "    axes[idx].set_yticklabels(['No Churn', 'Churn'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. ROC Curves\n",
    "\n",
    "# %%\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "for model_name, results in trainer.results.items():\n",
    "    y_pred_proba = results['y_pred_proba']\n",
    "    fpr, tpr, _ = roc_curve(trainer.y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    ax.plot(fpr, tpr, lw=2, label=f'{model_name.replace(\"_\", \" \").title()} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "# Plot diagonal line\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
    "\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curves - Model Comparison', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc=\"lower right\", fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Feature Importance (XGBoost)\n",
    "\n",
    "# %%\n",
    "# Get XGBoost model\n",
    "xgb_model = trainer.models['xgboost']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': trainer.feature_cols,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot top 15\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_15 = feature_importance.head(15)\n",
    "sns.barplot(data=top_15, y='Feature', x='Importance', palette='viridis')\n",
    "plt.title('Top 15 Feature Importance (XGBoost)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== TOP 10 MOST IMPORTANT FEATURES ===\\n\")\n",
    "print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Business Cost Analysis (CRITICAL FOR INTERVIEWS!)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üí∞ BUSINESS COST ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define costs\n",
    "FN_COST = 5000  # Cost of losing a customer\n",
    "FP_COST = 500   # Cost of retention offer\n",
    "\n",
    "print(f\"\\nüíµ Cost Assumptions:\")\n",
    "print(f\"   False Negative (missed churner): ‚Çπ{FN_COST:,}\")\n",
    "print(f\"   False Positive (wrong alert): ‚Çπ{FP_COST:,}\")\n",
    "print(f\"   Rationale: Acquiring new customer costs 10x retention\")\n",
    "\n",
    "# Calculate costs for each model\n",
    "print(f\"\\nüìä Total Business Cost per Model:\\n\")\n",
    "\n",
    "cost_comparison = []\n",
    "\n",
    "for model_name, results in trainer.results.items():\n",
    "    cm = results['confusion_matrix']\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    fn_total = fn * FN_COST\n",
    "    fp_total = fp * FP_COST\n",
    "    total_cost = fn_total + fp_total\n",
    "    cost_per_customer = total_cost / len(trainer.y_test)\n",
    "    \n",
    "    cost_comparison.append({\n",
    "        'Model': model_name.replace('_', ' ').title(),\n",
    "        'FN': fn,\n",
    "        'FP': fp,\n",
    "        'Total Cost': total_cost,\n",
    "        'Cost/Customer': cost_per_customer\n",
    "    })\n",
    "    \n",
    "    print(f\"{model_name.upper()}:\")\n",
    "    print(f\"   False Negatives: {fn} √ó ‚Çπ{FN_COST:,} = ‚Çπ{fn_total:,}\")\n",
    "    print(f\"   False Positives: {fp} √ó ‚Çπ{FP_COST:,} = ‚Çπ{fp_total:,}\")\n",
    "    print(f\"   Total Cost: ‚Çπ{total_cost:,}\")\n",
    "    print(f\"   Cost per Customer: ‚Çπ{cost_per_customer:.2f}\\n\")\n",
    "\n",
    "# Calculate do-nothing baseline\n",
    "total_churners = trainer.y_test.sum()\n",
    "do_nothing_cost = total_churners * FN_COST\n",
    "\n",
    "print(f\"DO NOTHING BASELINE:\")\n",
    "print(f\"   All churners lost: {total_churners} √ó ‚Çπ{FN_COST:,} = ‚Çπ{do_nothing_cost:,}\")\n",
    "print(f\"   Cost per Customer: ‚Çπ{do_nothing_cost/len(trainer.y_test):.2f}\")\n",
    "\n",
    "# Calculate savings\n",
    "print(f\"\\nüí° COST SAVINGS VS DO-NOTHING:\\n\")\n",
    "for item in cost_comparison:\n",
    "    savings = do_nothing_cost - item['Total Cost']\n",
    "    savings_pct = (savings / do_nothing_cost) * 100\n",
    "    print(f\"   {item['Model']}: ‚Çπ{savings:,} ({savings_pct:.1f}% reduction)\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. Cost Visualization\n",
    "\n",
    "# %%\n",
    "# Visualize costs\n",
    "cost_df = pd.DataFrame(cost_comparison)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Total cost\n",
    "axes[0].bar(cost_df['Model'], cost_df['Total Cost'], color=['#3498db', '#2ecc71'])\n",
    "axes[0].axhline(y=do_nothing_cost, color='red', linestyle='--', \n",
    "                label=f'Do Nothing: ‚Çπ{do_nothing_cost:,}')\n",
    "axes[0].set_title('Total Business Cost by Model', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Total Cost (‚Çπ)')\n",
    "axes[0].legend()\n",
    "axes[0].ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "# FN vs FP breakdown\n",
    "x = np.arange(len(cost_df))\n",
    "width = 0.35\n",
    "\n",
    "fn_costs = cost_df['FN'] * FN_COST\n",
    "fp_costs = cost_df['FP'] * FP_COST\n",
    "\n",
    "axes[1].bar(x, fn_costs, width, label='False Negative Cost', color='#e74c3c')\n",
    "axes[1].bar(x, fp_costs, width, bottom=fn_costs, label='False Positive Cost', color='#f39c12')\n",
    "axes[1].set_title('Cost Breakdown: FN vs FP', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Cost (‚Çπ)')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(cost_df['Model'])\n",
    "axes[1].legend()\n",
    "axes[1].ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/business_cost_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11. Prediction Examples\n",
    "\n",
    "# %%\n",
    "# Show some prediction examples\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ SAMPLE PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use XGBoost model\n",
    "xgb_model = trainer.models['xgboost']\n",
    "y_pred_proba = xgb_model.predict_proba(trainer.X_test)[:, 1]\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual_Churn': trainer.y_test.values,\n",
    "    'Churn_Probability': y_pred_proba,\n",
    "    'Risk_Level': pd.cut(y_pred_proba, bins=[0, 0.3, 0.7, 1.0], \n",
    "                         labels=['Low', 'Medium', 'High'])\n",
    "})\n",
    "\n",
    "# Show examples from each risk level\n",
    "print(\"\\nSample customers by risk level:\\n\")\n",
    "\n",
    "for risk in ['High', 'Medium', 'Low']:\n",
    "    print(f\"\\n{risk.upper()} RISK CUSTOMERS:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    samples = results_df[results_df['Risk_Level'] == risk].head(3)\n",
    "    for idx, row in samples.iterrows():\n",
    "        actual = \"CHURNED ‚ùå\" if row['Actual_Churn'] == 1 else \"RETAINED ‚úÖ\"\n",
    "        print(f\"  Probability: {row['Churn_Probability']:.2%} | Actual: {actual}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12. Model Selection Recommendation\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üèÜ MODEL SELECTION RECOMMENDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Determine best model based on business cost\n",
    "best_model = min(cost_comparison, key=lambda x: x['Total Cost'])\n",
    "\n",
    "print(f\"\"\"\n",
    "RECOMMENDED MODEL: {best_model['Model'].upper()}\n",
    "\n",
    "RATIONALE:\n",
    "1. Lowest Total Business Cost: ‚Çπ{best_model['Total Cost']:,}\n",
    "2. Best balance of False Negatives and False Positives\n",
    "3. Highest ROC-AUC score: {trainer.results[best_model['Model'].lower().replace(' ', '_')]['test_auc']:.4f}\n",
    "4. Production-ready with strong generalization\n",
    "\n",
    "DEPLOYMENT CONSIDERATIONS:\n",
    "- Set probability threshold to optimize cost (default: 0.5)\n",
    "- Monitor model performance weekly\n",
    "- Retrain quarterly with new data\n",
    "- A/B test retention campaigns\n",
    "\n",
    "EXPECTED IMPACT:\n",
    "- Identify {trainer.y_test.sum()} at-risk customers per cycle\n",
    "- Prevent ~{best_model['FN'] + (best_model['FP'] * 0.3):.0f} churns with interventions\n",
    "- Save ‚Çπ{do_nothing_cost - best_model['Total Cost']:,} vs do-nothing\n",
    "- ROI: {((do_nothing_cost - best_model['Total Cost']) / best_model['Total Cost'] * 100):.0f}%\n",
    "\n",
    "NEXT STEPS:\n",
    "1. Save model to production: ‚úÖ (already done in models/)\n",
    "2. Create API endpoint for real-time scoring\n",
    "3. Build monitoring dashboard\n",
    "4. Integrate with CRM for automated alerts\n",
    "\"\"\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 13. Save Final Report\n",
    "\n",
    "# %%\n",
    "# Create comprehensive report\n",
    "report_path = '../reports/modeling_final_report.txt'\n",
    "\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"CHURN PREDICTION - FINAL MODELING REPORT\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(\"MODELS TRAINED:\\n\")\n",
    "    f.write(\"-\"*70 + \"\\n\")\n",
    "    f.write(\"1. Logistic Regression (Baseline)\\n\")\n",
    "    f.write(\"2. XGBoost (Production Model)\\n\\n\")\n",
    "    \n",
    "    f.write(\"PERFORMANCE METRICS:\\n\")\n",
    "    f.write(\"-\"*70 + \"\\n\")\n",
    "    for model_name, results in trainer.results.items():\n",
    "        f.write(f\"\\n{model_name.upper()}:\\n\")\n",
    "        f.write(f\"  ROC-AUC: {results['test_auc']:.4f}\\n\")\n",
    "        f.write(f\"  Recall: {results['recall']:.4f}\\n\")\n",
    "        f.write(f\"  Precision: {results['precision']:.4f}\\n\")\n",
    "        f.write(f\"  F1-Score: {results['f1']:.4f}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    f.write(\"BUSINESS COST ANALYSIS:\\n\")\n",
    "    f.write(\"-\"*70 + \"\\n\")\n",
    "    for item in cost_comparison:\n",
    "        f.write(f\"\\n{item['Model']}:\\n\")\n",
    "        f.write(f\"  Total Cost: ‚Çπ{item['Total Cost']:,}\\n\")\n",
    "        f.write(f\"  Cost per Customer: ‚Çπ{item['Cost/Customer']:.2f}\\n\")\n",
    "    \n",
    "    f.write(f\"\\n\\nRECOMMENDED MODEL: {best_model['Model'].upper()}\\n\")\n",
    "    f.write(f\"Savings vs Do-Nothing: ‚Çπ{do_nothing_cost - best_model['Total Cost']:,}\\n\")\n",
    "\n",
    "print(f\"\\n‚úÖ Final report saved to: {report_path}\")\n",
    "print(\"\\nüéâ MODELING COMPLETE! Models are ready for production deployment.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
